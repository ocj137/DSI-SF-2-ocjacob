{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Project 7\n",
    "\n",
    "## NLP and Machine Learning on [travel.statsexchange.com](http://travel.stackexchange.com/) data\n",
    "\n",
    "---\n",
    "\n",
    "In Project 7 you'll be doing NLP and machine learning on post data from stackexchange's travel subdomain. \n",
    "\n",
    "This project is setup like a mini Kaggle competition. You are given the training data and when projects are submitted your model will be tested on the held-out testing data. There will be prizes for the people who build models that perform best on the held out test set!\n",
    "\n",
    "---\n",
    "\n",
    "## Notes on the data\n",
    "\n",
    "The data is again compressed into the `.7z` file format to save space. There are 6 .csv files and one readme file that contains some information on the fields.\n",
    "\n",
    "    posts_train.csv\n",
    "    comments_train.csv\n",
    "    users.csv\n",
    "    badges.csv\n",
    "    votes_train.csv\n",
    "    tags.csv\n",
    "    readme.txt\n",
    "    \n",
    "The data is located in your datasets folder:\n",
    "\n",
    "    DSI-SF-2/datasets/stack_exchange_travel.7z\n",
    "    \n",
    "If you're interested in where this data came from and where to get more data from other stackexchange subdomains, see here:\n",
    "\n",
    "https://ia800500.us.archive.org/22/items/stackexchange/readme.txt\n",
    "\n",
    "\n",
    "### Recommended Utilities for .7z\n",
    "\n",
    "- For OSX [Keka](http://www.kekaosx.com/en/) or [The Unarchiver](http://wakaba.c3.cx/s/apps/unarchiver.html). \n",
    "- For Windows [7-zip](http://www.7-zip.org/) is the standard. \n",
    "- For Linux try the `p7zip` utility.  `sudo apt-get install p7zip`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 1. Use LDA to find what topics are discussed on travel.stackexchange.com.\n",
    "\n",
    "---\n",
    "\n",
    "Text can be found in the posts and the comments datasets. The `ParentId` column in the posts dataset indicates what the \"question\" post was for a given post. Comment text can be merged onto the post they are part of with the `PostId` field.\n",
    "\n",
    "The text may have some HTML tags. BeautifulSoup has convenient ways to get rid of markup or extract text if you need to. You can also parse the strings yourself if you like.\n",
    "\n",
    "The tags dataset has the \"tags\" that the users have officially given the post.\n",
    "\n",
    "**1.1 Implement LDA against the text features of the dataset(s).**\n",
    "\n",
    "- This can be posts or a combination of posts and comments if you want more power.\n",
    "- Find optimal **K/num_topics**.\n",
    "\n",
    "**1.2 Compare your topics to the tags. Do the LDA topics make sense? How do they compare to the tags?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, matutils\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "travel_data = pd.read_csv('stack_exchange_travel/comments_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "travel_data1 = pd.read_csv('stack_exchange_travel/posts_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "travel_df = pd.DataFrame(travel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "travel_df1 = pd.DataFrame(travel_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>Body</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>CommunityOwnedDate</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>Id</th>\n",
       "      <th>LastActivityDate</th>\n",
       "      <th>...</th>\n",
       "      <th>LastEditorDisplayName</th>\n",
       "      <th>LastEditorUserId</th>\n",
       "      <th>OwnerDisplayName</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>ViewCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>393.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;p&gt;My fianc√©e and I are looking for a good Car...</td>\n",
       "      <td>2013-02-25T23:52:47.953</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:19:34.730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-05-24T14:52:14.760</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;caribbean&gt;&lt;cruising&gt;&lt;vacations&gt;</td>\n",
       "      <td>What are some Caribbean cruises for October?</td>\n",
       "      <td>361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;p&gt;Singapore Airlines has an all-business clas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:24:57.160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-09T09:55:22.743</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>693.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;loyalty-programs&gt;&lt;routes&gt;&lt;ewr&gt;&lt;singapore-airl...</td>\n",
       "      <td>Does Singapore Airlines offer any reward seats...</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>&lt;p&gt;Another definition question that interested...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:25:56.787</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-12T20:49:08.110</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;romania&gt;&lt;transportation&gt;</td>\n",
       "      <td>What is the easiest transportation to use thro...</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;p&gt;Can anyone suggest the best way to get from...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:30:38.687</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-03-28T03:41:28.130</td>\n",
       "      <td>...</td>\n",
       "      <td>user141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;usa&gt;&lt;airport-transfer&gt;&lt;taxis&gt;&lt;seattle&gt;</td>\n",
       "      <td>Best way to get from SeaTac airport to Redmond?</td>\n",
       "      <td>9219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;p&gt;We are considering visiting Argentina for u...</td>\n",
       "      <td>2016-01-02T10:26:48.277</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:31:21.800</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-01-01T21:58:02.303</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;sightseeing&gt;&lt;public-transport&gt;&lt;transportation...</td>\n",
       "      <td>What are must-visit destinations for the first...</td>\n",
       "      <td>1503.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AcceptedAnswerId  AnswerCount  \\\n",
       "0             393.0          4.0   \n",
       "1               NaN          1.0   \n",
       "2             770.0          5.0   \n",
       "3              62.0          3.0   \n",
       "4             178.0          4.0   \n",
       "\n",
       "                                                Body               ClosedDate  \\\n",
       "0  <p>My fianc√©e and I are looking for a good Car...  2013-02-25T23:52:47.953   \n",
       "1  <p>Singapore Airlines has an all-business clas...                      NaN   \n",
       "2  <p>Another definition question that interested...                      NaN   \n",
       "3  <p>Can anyone suggest the best way to get from...                      NaN   \n",
       "4  <p>We are considering visiting Argentina for u...  2016-01-02T10:26:48.277   \n",
       "\n",
       "   CommentCount CommunityOwnedDate             CreationDate  FavoriteCount  \\\n",
       "0             4                NaN  2011-06-21T20:19:34.730            NaN   \n",
       "1             1                NaN  2011-06-21T20:24:57.160            NaN   \n",
       "2             0                NaN  2011-06-21T20:25:56.787            2.0   \n",
       "3             2                NaN  2011-06-21T20:30:38.687            1.0   \n",
       "4             1                NaN  2011-06-21T20:31:21.800            8.0   \n",
       "\n",
       "   Id         LastActivityDate    ...    LastEditorDisplayName  \\\n",
       "0   1  2012-05-24T14:52:14.760    ...                      NaN   \n",
       "1   4  2013-01-09T09:55:22.743    ...                      NaN   \n",
       "2   5  2012-10-12T20:49:08.110    ...                      NaN   \n",
       "3   8  2016-03-28T03:41:28.130    ...                  user141   \n",
       "4   9  2016-01-01T21:58:02.303    ...                      NaN   \n",
       "\n",
       "  LastEditorUserId  OwnerDisplayName OwnerUserId  ParentId  PostTypeId  Score  \\\n",
       "0            101.0               NaN         9.0       NaN           1      8   \n",
       "1            693.0               NaN        24.0       NaN           1      8   \n",
       "2            101.0               NaN        13.0       NaN           1     11   \n",
       "3              NaN               NaN        26.0       NaN           1     11   \n",
       "4            101.0               NaN        23.0       NaN           1     12   \n",
       "\n",
       "                                                Tags  \\\n",
       "0                   <caribbean><cruising><vacations>   \n",
       "1  <loyalty-programs><routes><ewr><singapore-airl...   \n",
       "2                          <romania><transportation>   \n",
       "3            <usa><airport-transfer><taxis><seattle>   \n",
       "4  <sightseeing><public-transport><transportation...   \n",
       "\n",
       "                                               Title ViewCount  \n",
       "0       What are some Caribbean cruises for October?     361.0  \n",
       "1  Does Singapore Airlines offer any reward seats...     219.0  \n",
       "2  What is the easiest transportation to use thro...     340.0  \n",
       "3    Best way to get from SeaTac airport to Redmond?    9219.0  \n",
       "4  What are must-visit destinations for the first...    1503.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_travel_df = pd.concat([travel_df, travel_df1], axis=1, join='inner')\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(total_travel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'acceptedanswerid': 0,\n",
       " u'answercount': 1,\n",
       " u'body': 2,\n",
       " u'closeddate': 3,\n",
       " u'commentcount': 4,\n",
       " u'communityowneddate': 5,\n",
       " u'creationdate': 6,\n",
       " u'favoritecount': 7,\n",
       " u'id': 8,\n",
       " u'lastactivitydate': 9,\n",
       " u'lasteditdate': 10,\n",
       " u'lasteditordisplayname': 11,\n",
       " u'lasteditoruserid': 12,\n",
       " u'ownerdisplayname': 13,\n",
       " u'owneruserid': 14,\n",
       " u'parentid': 15,\n",
       " u'postid': 16,\n",
       " u'posttypeid': 17,\n",
       " u'score': 18,\n",
       " u'tags': 19,\n",
       " u'text': 20,\n",
       " u'title': 21,\n",
       " u'userdisplayname': 22,\n",
       " u'userid': 23,\n",
       " u'viewcount': 24}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceptedanswerid</th>\n",
       "      <th>answercount</th>\n",
       "      <th>body</th>\n",
       "      <th>closeddate</th>\n",
       "      <th>commentcount</th>\n",
       "      <th>communityowneddate</th>\n",
       "      <th>creationdate</th>\n",
       "      <th>favoritecount</th>\n",
       "      <th>id</th>\n",
       "      <th>lastactivitydate</th>\n",
       "      <th>...</th>\n",
       "      <th>parentid</th>\n",
       "      <th>postid</th>\n",
       "      <th>posttypeid</th>\n",
       "      <th>score</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>userdisplayname</th>\n",
       "      <th>userid</th>\n",
       "      <th>viewcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acceptedanswerid  answercount  body  closeddate  commentcount  \\\n",
       "0                 0            0     0           0             0   \n",
       "1                 0            0     0           0             0   \n",
       "2                 0            0     0           0             0   \n",
       "3                 0            0     0           0             0   \n",
       "4                 0            0     0           0             0   \n",
       "\n",
       "   communityowneddate  creationdate  favoritecount  id  lastactivitydate  \\\n",
       "0                   0             1              0   0                 0   \n",
       "1                   0             0              0   1                 0   \n",
       "2                   0             0              0   0                 0   \n",
       "3                   0             0              0   0                 0   \n",
       "4                   0             0              0   0                 0   \n",
       "\n",
       "     ...      parentid  postid  posttypeid  score  tags  text  title  \\\n",
       "0    ...             0       0           0      0     0     0      0   \n",
       "1    ...             0       0           0      0     0     0      0   \n",
       "2    ...             0       1           0      0     0     0      0   \n",
       "3    ...             0       0           0      1     0     0      0   \n",
       "4    ...             0       0           0      0     0     1      0   \n",
       "\n",
       "   userdisplayname  userid  viewcount  \n",
       "0                0       0          0  \n",
       "1                0       0          0  \n",
       "2                0       0          0  \n",
       "3                0       0          0  \n",
       "4                0       0          0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: u'acceptedanswerid',\n",
       " 1: u'answercount',\n",
       " 2: u'body',\n",
       " 3: u'closeddate',\n",
       " 4: u'commentcount',\n",
       " 5: u'communityowneddate',\n",
       " 6: u'creationdate',\n",
       " 7: u'favoritecount',\n",
       " 8: u'id',\n",
       " 9: u'lastactivitydate',\n",
       " 10: u'lasteditdate',\n",
       " 11: u'lasteditordisplayname',\n",
       " 12: u'lasteditoruserid',\n",
       " 13: u'ownerdisplayname',\n",
       " 14: u'owneruserid',\n",
       " 15: u'parentid',\n",
       " 16: u'postid',\n",
       " 17: u'posttypeid',\n",
       " 18: u'score',\n",
       " 19: u'tags',\n",
       " 20: u'text',\n",
       " 21: u'title',\n",
       " 22: u'userdisplayname',\n",
       " 23: u'userid',\n",
       " 24: u'viewcount'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {v: k for k, v in vectorizer.vocabulary_.iteritems()}\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = models.LdaModel(\n",
    "    matutils.Sparse2Corpus(X, documents_columns=False),\n",
    "    # or use the corpus object created with the dictionary in the previous frame!\n",
    "    # corpus, \n",
    "    num_topics  =  3,\n",
    "    passes      =  20,\n",
    "    id2word     =  vocab\n",
    "    # or use the gensim dictionary object!\n",
    "    # id2word     =  dictionary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)\n",
    "\n",
    "documents = total_travel_df\n",
    "\n",
    "for text in documents:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "          for text in documents]\n",
    "\n",
    "# Create gensim dictionary object\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# Create corpus matrix\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.115*score + 0.115*id + 0.065*ownerdisplayname + 0.065*lasteditordisplayname + 0.065*favoritecount + 0.065*commentcount + 0.065*communityowneddate'),\n",
       " (1,\n",
       "  u'0.127*creationdate + 0.072*answercount + 0.072*userdisplayname + 0.072*owneruserid + 0.072*acceptedanswerid + 0.072*title + 0.072*lasteditoruserid'),\n",
       " (2,\n",
       "  u'0.092*tags + 0.092*lastactivitydate + 0.092*closeddate + 0.092*posttypeid + 0.092*text + 0.092*body + 0.023*parentid')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(num_topics=3, num_words=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.42871581994060687), (1, 0.11272744051023298), (2, 0.4585567395491601)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_document_topics(corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 2. What makes an answer likely to be \"accepted\"?\n",
    "\n",
    "---\n",
    "\n",
    "**2.1 Build a model to predict whether a post will be marked as the answer.**\n",
    "\n",
    "- This is a classification problem.\n",
    "- You're free to use any of the machine learning algorithms or techniques we have learned in class to build the best model you can.\n",
    "- NLP will be very useful here for pulling out useful and relevant features from the data. \n",
    "- Though not required, using bagging and boosting models like Random Forests and Gradient Boosted Trees will _probably_ get you the highest performance on the test data (but who knows!).\n",
    "\n",
    "\n",
    "**2.2 Evaluate the performance of your classifier with a confusion matrix and accuracy. Explain how your model is performing.**\n",
    "\n",
    "**2.3 Plot either a ROC curve or precision-recall curve (or both!) and explain what they tell you about your model.**\n",
    "\n",
    "NOTE: You should only be predicting this for `PostTypeID=2` posts, which are the \"answer\" posts. This doesn't mean, however, that you can't or shouldn't use the parent questions as predictors!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "5        1\n",
       "6        1\n",
       "7        1\n",
       "8        1\n",
       "9        2\n",
       "10       2\n",
       "11       2\n",
       "12       1\n",
       "13       1\n",
       "14       1\n",
       "15       1\n",
       "16       2\n",
       "17       1\n",
       "18       2\n",
       "19       1\n",
       "20       1\n",
       "21       2\n",
       "22       2\n",
       "23       2\n",
       "24       2\n",
       "25       2\n",
       "26       2\n",
       "27       2\n",
       "28       1\n",
       "29       2\n",
       "        ..\n",
       "41259    1\n",
       "41260    2\n",
       "41261    2\n",
       "41262    2\n",
       "41263    2\n",
       "41264    1\n",
       "41265    2\n",
       "41266    1\n",
       "41267    1\n",
       "41268    2\n",
       "41269    2\n",
       "41270    2\n",
       "41271    2\n",
       "41272    2\n",
       "41273    2\n",
       "41274    5\n",
       "41275    4\n",
       "41276    1\n",
       "41277    2\n",
       "41278    2\n",
       "41279    2\n",
       "41280    2\n",
       "41281    1\n",
       "41282    2\n",
       "41283    2\n",
       "41284    2\n",
       "41285    2\n",
       "41286    2\n",
       "41287    1\n",
       "41288    2\n",
       "Name: PostTypeId, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_travel_df.PostTypeId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_travel_df['accepted'] = total_travel_df['PostTypeId'] - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvec2 = CountVectorizer(stop_words = 'english', ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2 = cvec2.fit_transform(total_travel_df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y2 =  total_travel_df['accepted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41289,), (41289, 977288))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2.shape, X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.utils import shuffle\n",
    "#X_shuf, Y_shuf = shuffle(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24773, 977288), (24773,))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape, y_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg2 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg2.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 3. What is the score of a post?\n",
    "\n",
    "---\n",
    "\n",
    "**3.1 Build a model that predicts the score of a post.**\n",
    "\n",
    "- This is a regression problem now. \n",
    "- You can and should be predicting score for both \"question\" and \"answer\" posts, so keep them both in your dataset.\n",
    "- Again, use any techniques that you think will get you the best model.\n",
    "\n",
    "**3.2 Evaluate the performance of your model with cross-validation and report the results.**\n",
    "\n",
    "**3.3 What is important for determining the score of a post, if anything?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 4. How many views does a post have?\n",
    "\n",
    "---\n",
    "\n",
    "**4.1 Build a model that predicts the number of views a post has.**\n",
    "\n",
    "- This is another regression problem. \n",
    "- Predict the views for all posts, not just the \"answer\" posts.\n",
    "\n",
    "**4.2 Evaluate the performance of your model with cross-validation and report the results.**\n",
    "\n",
    "**4.3 What is important for the number of views a post has, if anything?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 5. Build a pipeline or other code to automate evaluation of your models on the test data.\n",
    "\n",
    "---\n",
    "\n",
    "Now that you've constructed your three predictive models, build a pipeline or code that can easily load up the raw testing data and evaluate your models on it.\n",
    "\n",
    "The testing data that is held out is in the same raw format as the training data you have. _Any cleaning and preprocessing that you did on the training data will need to be done on the testing data as well!_\n",
    "\n",
    "This is a good opportunity to practice building pipelines, but you're not required to. Custom functions and classes are fine as long as they are able to process and test the new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
